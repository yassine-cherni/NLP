{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7CjgwdokTnX8+bWHpwagY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yassine-cherni/NLP/blob/main/Haw_yetrana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mfFD9jPfzPjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d910c922-1700-457f-b3eb-82b55e16a499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "from IPython import display\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# Set the seed value for experiment reproducibility.\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Define dataset path\n",
        "DATASET_PATH = '/content/drive/MyDrive/DATA/AUDIO'\n",
        "data_dir = pathlib.Path(DATASET_PATH)\n",
        "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
        "print('Commands:', commands)\n",
        "\n",
        "# Load dataset\n",
        "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
        "    directory=data_dir,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    seed=0,\n",
        "    output_sequence_length=16000,\n",
        "    subset='both'\n",
        ")\n",
        "\n",
        "label_names = np.array(train_ds.class_names)\n",
        "print(\"Label names:\", label_names)\n",
        "\n",
        "def squeeze(audio, labels):\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    return audio, labels\n",
        "\n",
        "train_ds = train_ds.map(squeeze, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(squeeze, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = val_ds.shard(num_shards=2, index=0)\n",
        "val_ds = val_ds.shard(num_shards=2, index=1)\n",
        "\n",
        "def get_spectrogram(waveform):\n",
        "    spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = spectrogram[..., tf.newaxis]\n",
        "    return spectrogram\n",
        "\n",
        "def plot_spectrogram(spectrogram, ax):\n",
        "    if len(spectrogram.shape) > 2:\n",
        "        assert len(spectrogram.shape) == 3\n",
        "        spectrogram = np.squeeze(spectrogram, axis=-1)\n",
        "    log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
        "    height = log_spec.shape[0]\n",
        "    width = log_spec.shape[1]\n",
        "    X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
        "    Y = range(height)\n",
        "    ax.pcolormesh(X, Y, log_spec)\n",
        "\n",
        "def make_spec_ds(ds):\n",
        "    return ds.map(map_func=lambda audio, label: (get_spectrogram(audio), label), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_spectrogram_ds = make_spec_ds(train_ds)\n",
        "val_spectrogram_ds = make_spec_ds(val_ds)\n",
        "test_spectrogram_ds = make_spec_ds(test_ds)\n",
        "\n",
        "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
        "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "input_shape = (124, 129, 1)  # Spectrogram shape\n",
        "num_labels = len(label_names)\n",
        "\n",
        "# Create the model\n",
        "inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "# Resizing and normalization\n",
        "x = layers.Resizing(224, 224)(inputs)\n",
        "norm_layer = layers.Normalization()\n",
        "norm_layer.adapt(train_spectrogram_ds.map(lambda spec, label: spec))\n",
        "x = norm_layer(x)\n",
        "\n",
        "# Convert to 3 channels for ResNet50\n",
        "x = layers.Conv2D(3, (3, 3), padding='same')(x)\n",
        "\n",
        "# Load pre-trained ResNet50 model\n",
        "base_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "# Add output layers\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Reshape((1, x.shape[-1]))(x)  # Reshape for LSTM\n",
        "x = layers.LSTM(128)(x)  # LSTM layer\n",
        "\n",
        "outputs = layers.Dense(num_labels)(x)  # Final output layer\n",
        "\n",
        "# Build and compile the model\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 100\n",
        "history = model.fit(\n",
        "    train_spectrogram_ds,\n",
        "    validation_data=val_spectrogram_ds,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwEshEEG0Sou",
        "outputId": "b6e56b14-8503-47c2-b524-5bb247146b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Commands: ['LIGHT_ON' 'DISABLE_LANE_ASSIST' 'TURN_Off_VENTILATION'\n",
            " 'TURN_ON_VENTILATION' 'POWER_ON_FOCUS' 'POWER_OFF_FOCUS'\n",
            " 'ACTIVATE_LANE_ASSIST' 'LIGHT_OFF' 'speech_recognition_model.h5'\n",
            " 'speech_recognition_model.keras']\n",
            "Found 8014 files belonging to 8 classes.\n",
            "Using 6412 files for training.\n",
            "Using 1602 files for validation.\n",
            "Label names: ['ACTIVATE_LANE_ASSIST' 'DISABLE_LANE_ASSIST' 'LIGHT_OFF' 'LIGHT_ON'\n",
            " 'POWER_OFF_FOCUS' 'POWER_ON_FOCUS' 'TURN_ON_VENTILATION'\n",
            " 'TURN_Off_VENTILATION']\n"
          ]
        }
      ]
    }
  ]
}